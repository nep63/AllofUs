{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1: Set UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ~/aou_dsub.bash\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "# This shell function passes reasonable defaults for several dsub parameters, while\n",
    "# allowing the caller to override any of them. It creates a nice folder structure within\n",
    "# the workspace bucket for dsub log files.\n",
    "\n",
    "# --[ Parameters ]--\n",
    "# any valid dsub parameter flag\n",
    "\n",
    "#--[ Returns ]--\n",
    "# the job id of the job created by dsub\n",
    "\n",
    "#--[ Details ]--\n",
    "# The first five parameters below should always be those values when running on AoU RWB.\n",
    "\n",
    "# Feel free to change the values for --user, --regions, --logging, and --image if you like.\n",
    "\n",
    "# Note that we insert some job data into the logging path.\n",
    "# https://github.com/DataBiosphere/dsub/blob/main/docs/logging.md#inserting-job-data\n",
    "\n",
    "function aou_dsub () {\n",
    "\n",
    "  # Get a shorter username to leave more characters for the job name.\n",
    "  local DSUB_USER_NAME=\"$(echo \"${OWNER_EMAIL}\" | cut -d@ -f1)\"\n",
    "\n",
    "  # For AoU RWB projects network name is \"network\".\n",
    "  local AOU_NETWORK=network\n",
    "  local AOU_SUBNETWORK=subnetwork\n",
    "\n",
    "  dsub \\\n",
    "      --provider google-cls-v2 \\\n",
    "      --user-project \"${GOOGLE_PROJECT}\"\\\n",
    "      --project \"${GOOGLE_PROJECT}\"\\\n",
    "      --image 'marketplace.gcr.io/google/ubuntu1804:latest' \\\n",
    "      --network \"${AOU_NETWORK}\" \\\n",
    "      --subnetwork \"${AOU_SUBNETWORK}\" \\\n",
    "      --service-account \"$(gcloud config get-value account)\" \\\n",
    "      --user \"${DSUB_USER_NAME}\" \\\n",
    "      --regions us-central1 \\\n",
    "      --logging \"${WORKSPACE_BUCKET}/dsub/logs/{job-name}/{user-id}/$(date +'%Y%m%d/%H%M%S')/{job-id}-{task-id}-{task-attempt}.log\" \\\n",
    "      \"$@\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: Copy over files to annotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source ~/aou_dsub.bash\n",
    "\n",
    "USER_NAME=${USER_NAME:-$(whoami)}\n",
    "JOB_NAME=\"copy-vcf-files-${USER_NAME}\"\n",
    "\n",
    "# Define source and destination bucket paths\n",
    "ORIGINAL_BUCKET=\"gs://fc-secure-5e490ca2-d5ae-40a3-aa5e-7355e31ab9cc/newID_PLINK\"\n",
    "SECURE_BUCKET=\"gs://fc-secure-5e490ca2-d5ae-40a3-aa5e-7355e31ab9cc/chr_newID\"\n",
    "\n",
    "aou_dsub \\\n",
    "  --name \"${JOB_NAME}_copy\" \\\n",
    "  --image \"gcr.io/google.com/cloudsdktool/cloud-sdk\" \\\n",
    "  --logging \"${SECURE_BUCKET}/logging\" \\\n",
    "  --min-cores 2 \\\n",
    "  --min-ram 4 \\\n",
    "  --boot-disk-size 50 \\\n",
    "  --disk-size 500 \\\n",
    "  --command \"\n",
    "    set -ex\n",
    "    echo 'Starting VCF file copy process...'\n",
    "    \n",
    "    for CHR in {1..22}; do\n",
    "      echo \\\"Copying chromosome \\$CHR...\\\"\n",
    "      gsutil -u ${GOOGLE_PROJECT} cp ${ORIGINAL_BUCKET}/exome_v8.chr\\${CHR}.new_id.split_multiallelic.sites_only.pass_qc.vcf.gz ${SECURE_BUCKET}/\n",
    "    done\n",
    "    \n",
    "    echo 'VCF file copy process completed successfully.'\n",
    "  \" \\\n",
    "  --wait\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Replace BUCKET_PATH with your actual GCS bucket path\n",
    "BUCKET_PATH=\"gs://fc-secure-5e490ca2-d5ae-40a3-aa5e-7355e31ab9cc/vep/cache\"\n",
    "\n",
    "# Download the required cache files from Ensembl to your local machine or VM with minimal output\n",
    "wget --progress=dot:giga -P ./ \\\n",
    "  https://ftp.ensembl.org/pub/release-113/variation/indexed_vep_cache/homo_sapiens_vep_113_GRCh38.tar.gz\n",
    "\n",
    "wget --progress=dot:giga -P ./ \\\n",
    "  https://ftp.ensembl.org/pub/release-113/variation/indexed_vep_cache/homo_sapiens_merged_vep_113_GRCh38.tar.gz\n",
    "\n",
    "wget --progress=dot:giga -P ./ \\\n",
    "  https://ftp.ensembl.org/pub/release-113/variation/indexed_vep_cache/homo_sapiens_refseq_vep_113_GRCh38.tar.gz\n",
    "\n",
    "# Upload the files to your GCS bucket\n",
    "gsutil cp homo_sapiens_*.tar.gz $BUCKET_PATH/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3: Run VEP to annotate and NOTE, adjust your parameters based off of how big your files are and how much resources are available "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Also this step includes extracting your cache files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "source ~/aou_dsub.bash\n",
    "\n",
    "#This is just for chr1 since it is massive\n",
    "\n",
    "USER_NAME=${USER_NAME:-$(whoami)}\n",
    "JOB_NAME=\"vep-test-lof-${USER_NAME}\"\n",
    "\n",
    "# Define bucket locations for required files\n",
    "PLUGIN_BUCKET=\"gs://fc-secure-5e490ca2-d5ae-40a3-aa5e-7355e31ab9cc/vep/plugins\"\n",
    "CACHE_BUCKET=\"gs://fc-secure-5e490ca2-d5ae-40a3-aa5e-7355e31ab9cc/vep/cache\"\n",
    "VCF_BUCKET=\"gs://fc-secure-5e490ca2-d5ae-40a3-aa5e-7355e31ab9cc/chr_newID\"\n",
    "\n",
    "EXT_BUCKET=\"gs://fc-secure-5e490ca2-d5ae-40a3-aa5e-7355e31ab9cc/vep/cache/extracted\"\n",
    "OUTPUT_BUCKET=\"gs://fc-secure-5e490ca2-d5ae-40a3-aa5e-7355e31ab9cc/vep/output\"\n",
    "\n",
    "aou_dsub \\\n",
    "  --name \"${JOB_NAME}\" \\\n",
    "  --project \"${GOOGLE_PROJECT}\" \\\n",
    "  --image \"gcr.io/ritchie-aou-psom-9015/ensembl-vep:latest\" \\\n",
    "  --logging \"${OUTPUT_BUCKET}/logging\" \\\n",
    "  --min-cores 32 \\\n",
    "  --min-ram 128 \\\n",
    "  --disk-size 3000 \\\n",
    "  --input-recursive input_lof_plugin=\"${PLUGIN_BUCKET}\" \\\n",
    "  --input-recursive input_cache=\"${CACHE_BUCKET}\" \\\n",
    "  --input-recursive input_vcf=\"${VCF_BUCKET}\" \\\n",
    "  --output-recursive extracted_cache=\"${EXT_BUCKET}\" \\\n",
    "  --output-recursive output=\"${OUTPUT_BUCKET}\" \\\n",
    "  --command \"\n",
    "    set -ex\n",
    "\n",
    "    # Localized paths\n",
    "    PLUGIN_DIR=/mnt/data/input/gs/fc-secure-5e490ca2-d5ae-40a3-aa5e-7355e31ab9cc/vep/plugins\n",
    "    # Expect LoFTEE files in the loftee subdirectory\n",
    "    HUMAN_ANCESTOR_FILE=\\${PLUGIN_DIR}/human_ancestor.fa.gz\n",
    "    HUMAN_ANCESTOR_INDEX=\\${PLUGIN_DIR}/human_ancestor.fa.gz.fai\n",
    "    CONSERVATION_FILE=\\${PLUGIN_DIR}/loftee.sql\n",
    "    GERP_FILE_PATH=\\${PLUGIN_DIR}/gerp_conservation_scores.homo_sapiens.GRCh38.bw\n",
    "    CACHE_DIR=/mnt/data/input/gs/fc-secure-5e490ca2-d5ae-40a3-aa5e-7355e31ab9cc/vep/cache\n",
    "    EXTRACTED_CACHE_DIR=/mnt/data/output/gs/fc-secure-5e490ca2-d5ae-40a3-aa5e-7355e31ab9cc/vep/cache/extracted\n",
    "    # Define test VCF for chromosome 1\n",
    "    TEST_VCF=/mnt/data/input/gs/fc-secure-5e490ca2-d5ae-40a3-aa5e-7355e31ab9cc/chr_newID/exome_v8.chr1.new_id.split_multiallelic.sites_only.pass_qc.vcf.gz\n",
    "\n",
    "    # Export environment variables needed for VEP\n",
    "    export PERL5LIB=/opt/vep/src/ensembl-vep/modules:/opt/vep/src/bioperl-live:\\$PERL5LIB:/mnt/data/input/gs/fc-secure-5e490ca2-d5ae-40a3-aa5e31ab9cc/vep/plugins\n",
    "    # Use the loftee subdirectory for LOFTEE files\n",
    "    export LOFTEE_DIR=\\${PLUGIN_DIR}/loftee\n",
    "\n",
    "    echo 'Listing contents of the plugins directory:'\n",
    "    ls -lh \\${PLUGIN_DIR}\n",
    "\n",
    "    echo 'Listing contents of the cache directory:'\n",
    "    ls -lh \\${CACHE_DIR}\n",
    "\n",
    "    echo 'Extracting VEP cache files:'\n",
    "    CACHE_FILES=(homo_sapiens_vep_113_GRCh38.tar.gz homo_sapiens_merged_vep_113_GRCh38.tar.gz homo_sapiens_refseq_vep_113_GRCh38.tar.gz)\n",
    "    for FILE in \\\"\\${CACHE_FILES[@]}\\\"; do\n",
    "      FULL_PATH=\\\"\\${CACHE_DIR}/\\${FILE}\\\"\n",
    "      if [[ -f \\\"\\${FULL_PATH}\\\" ]]; then\n",
    "        echo \\\"Extracting \\${FULL_PATH}...\\\"\n",
    "        tar -xzf \\\"\\${FULL_PATH}\\\" -C \\\"\\${EXTRACTED_CACHE_DIR}\\\"\n",
    "      else\n",
    "        echo \\\"WARNING: File \\${FULL_PATH} not found! Skipping...\\\"\n",
    "      fi\n",
    "    done\n",
    "\n",
    "    echo 'Listing extracted cache contents:'\n",
    "    ls -lh \\${EXTRACTED_CACHE_DIR}\n",
    "\n",
    "    echo 'Listing the test VCF file:'\n",
    "    ls -lh \\${TEST_VCF}\n",
    "\n",
    "    # Define the main output file\n",
    "    OUTPUT_FILE=/mnt/data/output/gs/fc-secure-5e490ca2-d5ae-40a3-aa5e-7355e31ab9cc/vep/output/AOU_v8.finalAnnot.chr1.new_id.split_multiallelic.sites_only.pass_qc.txt\n",
    "\n",
    "    echo 'Running VEP with the LoF plugin on chromosome 1...'\n",
    "    perl /opt/vep/src/ensembl-vep/vep \\\\\n",
    "      -i \\${TEST_VCF} \\\\\n",
    "      -o \\${OUTPUT_FILE} \\\\\n",
    "      --warning_file /tmp/vep_warnings.txt \\\\\n",
    "      --plugin LoF,loftee_path:\\${PLUGIN_DIR}/loftee,human_ancestor_fa:\\${HUMAN_ANCESTOR_FILE},human_ancestor_index:\\${HUMAN_ANCESTOR_INDEX},conservation_file:\\${CONSERVATION_FILE},gerp_bigwig:\\${GERP_FILE_PATH} \\\\\n",
    "      --plugin CADD,snv=\\${PLUGIN_DIR}/whole_genome_SNVs_inclAnno.tsv.gz,indels=\\${PLUGIN_DIR}/whole_genome_SNVs_inclAnno.tsv.gz \\\\\n",
    "      --plugin dbNSFP,\\${PLUGIN_DIR}/dbNSFP/dbNSFP4.9a_grch38.gz,Ensembl_transcriptid,Uniprot_acc,VEP_canonical,LRT_pred,SIFT_pred,MutationTaster_pred,Polyphen2_HDIV_pred,Polyphen2_HVAR_pred,REVEL_score \\\\\n",
    "      --plugin SpliceAI,snv=\\${PLUGIN_DIR}/spliceai_scores.raw.snv.hg38.vcf.gz,indel=\\${PLUGIN_DIR}/spliceai_scores.raw.indel.hg38.vcf.gz \\\\\n",
    "      --everything \\\\\n",
    "      --buffer_size 40000 \\\\\n",
    "      --fork 24 \\\\\n",
    "      --minimal \\\\\n",
    "      --offline \\\\\n",
    "      --dir_cache \\${EXTRACTED_CACHE_DIR} \\\\\n",
    "      --no_escape \\\\\n",
    "      --fasta \\${PLUGIN_DIR}/Homo_sapiens_assembly38.fasta \\\\\n",
    "      --hgvs \\\\\n",
    "      --cache \\\\\n",
    "      --format vcf \\\\\n",
    "      --force_overwrite \\\\\n",
    "      --tab \\\\\n",
    "      --dir_plugins \\${PLUGIN_DIR}\n",
    "\n",
    "    echo 'VEP run completed. Check the output at:' \\${OUTPUT_FILE}\n",
    "  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "source ~/aou_dsub.bash\n",
    "\n",
    "USER_NAME=${USER_NAME:-$(whoami)}\n",
    "JOB_PREFIX=\"vep-test-lof-${USER_NAME}\"\n",
    "\n",
    "# Define bucket locations for required files\n",
    "PLUGIN_BUCKET=\"gs://fc-secure-5e490ca2-d5ae-40a3-aa5e-7355e31ab9cc/vep/plugins\"\n",
    "CACHE_BUCKET=\"gs://fc-secure-5e490ca2-d5ae-40a3-aa5e-7355e31ab9cc/vep/cache\"\n",
    "VCF_BUCKET=\"gs://fc-secure-5e490ca2-d5ae-40a3-aa5e-7355e31ab9cc/chr_newID\"\n",
    "\n",
    "EXT_BUCKET=\"gs://fc-secure-5e490ca2-d5ae-40a3-aa5e-7355e31ab9cc/vep/cache/extracted\"\n",
    "OUTPUT_BUCKET=\"gs://fc-secure-5e490ca2-d5ae-40a3-aa5e-7355e31ab9cc/vep/output\"\n",
    "\n",
    "# Function to run a VEP job for a given chromosome number.\n",
    "run_vep_job() {\n",
    "  local CHR=$1\n",
    "  local JOB_NAME=\"${JOB_PREFIX}-chr${CHR}\"\n",
    "  \n",
    "  aou_dsub \\\n",
    "    --name \"${JOB_NAME}\" \\\n",
    "    --project \"${GOOGLE_PROJECT}\" \\\n",
    "    --image \"gcr.io/ritchie-aou-psom-9015/ensembl-vep:latest\" \\\n",
    "    --logging \"${OUTPUT_BUCKET}/logging\" \\\n",
    "    --min-cores 32 \\\n",
    "    --min-ram 128 \\\n",
    "    --disk-size 3000 \\\n",
    "    --input-recursive input_lof_plugin=\"${PLUGIN_BUCKET}\" \\\n",
    "    --input-recursive input_cache=\"${CACHE_BUCKET}\" \\\n",
    "    --input-recursive input_vcf=\"${VCF_BUCKET}\" \\\n",
    "    --output-recursive extracted_cache=\"${EXT_BUCKET}\" \\\n",
    "    --output-recursive output=\"${OUTPUT_BUCKET}\" \\\n",
    "    --command \"\n",
    "      set -ex\n",
    "      \n",
    "      # Localized paths\n",
    "      PLUGIN_DIR=/mnt/data/input/gs/fc-secure-5e490ca2-d5ae-40a3-aa5e-7355e31ab9cc/vep/plugins\n",
    "      # Use the loftee subdirectory for LoFTEE files\n",
    "      HUMAN_ANCESTOR_FILE=\\${PLUGIN_DIR}/human_ancestor.fa.gz\n",
    "      HUMAN_ANCESTOR_INDEX=\\${PLUGIN_DIR}/human_ancestor.fa.gz.fai\n",
    "      CONSERVATION_FILE=\\${PLUGIN_DIR}/loftee.sql\n",
    "      GERP_FILE_PATH=\\${PLUGIN_DIR}/gerp_conservation_scores.homo_sapiens.GRCh38.bw\n",
    "      CACHE_DIR=/mnt/data/input/gs/fc-secure-5e490ca2-d5ae-40a3-aa5e-7355e31ab9cc/vep/cache\n",
    "      EXTRACTED_CACHE_DIR=/mnt/data/output/gs/fc-secure-5e490ca2-d5ae-40a3-aa5e-7355e31ab9cc/vep/cache/extracted\n",
    "      # IMPORTANT: Remove the backslash so the variable expands.\n",
    "      TEST_VCF=/mnt/data/input/gs/fc-secure-5e490ca2-d5ae-40a3-aa5e-7355e31ab9cc/chr_newID/exome_v8.chr${CHR}.new_id.split_multiallelic.sites_only.pass_qc.vcf.gz\n",
    "      \n",
    "      # Export environment variables needed for VEP.\n",
    "      export PERL5LIB=/opt/vep/src/ensembl-vep/modules:/opt/vep/src/bioperl-live:\\$PERL5LIB:/mnt/data/input/gs/fc-secure-5e490ca2-d5ae-40a3-aa5e-7355e31ab9cc/vep/plugins\n",
    "      export LOFTEE_DIR=\\${PLUGIN_DIR}/loftee\n",
    "      \n",
    "      echo 'Listing contents of the plugins directory:'\n",
    "      ls -lh \\${PLUGIN_DIR}\n",
    "      \n",
    "      echo 'Listing contents of the cache directory:'\n",
    "      ls -lh \\${CACHE_DIR}\n",
    "      \n",
    "      echo 'Extracting VEP cache files:'\n",
    "      CACHE_FILES=(homo_sapiens_vep_113_GRCh38.tar.gz homo_sapiens_merged_vep_113_GRCh38.tar.gz homo_sapiens_refseq_vep_113_GRCh38.tar.gz)\n",
    "      for FILE in \\\"\\${CACHE_FILES[@]}\\\"; do\n",
    "        FULL_PATH=\\\"\\${CACHE_DIR}/\\${FILE}\\\"\n",
    "        if [[ -f \\\"\\${FULL_PATH}\\\" ]]; then\n",
    "          echo \\\"Extracting \\${FULL_PATH}...\\\"\n",
    "          tar -xzf \\\"\\${FULL_PATH}\\\" -C \\\"\\${EXTRACTED_CACHE_DIR}\\\"\n",
    "        else\n",
    "          echo \\\"WARNING: File \\${FULL_PATH} not found! Skipping...\\\"\n",
    "        fi\n",
    "      done\n",
    "      \n",
    "      echo 'Listing extracted cache contents:'\n",
    "      ls -lh \\${EXTRACTED_CACHE_DIR}\n",
    "      \n",
    "      echo 'Listing the test VCF file:'\n",
    "      ls -lh \\${TEST_VCF}\n",
    "      \n",
    "      # Define the main output file.\n",
    "      OUTPUT_FILE=/mnt/data/output/gs/fc-secure-5e490ca2-d5ae-40a3-aa5e-7355e31ab9cc/vep/output/AOU_v8.finalAnnot.chr${CHR}.new_id.split_multiallelic.sites_only.pass_qc.txt\n",
    "      \n",
    "      echo 'Running VEP with the LoF plugin on chromosome ${CHR}...'\n",
    "      perl /opt/vep/src/ensembl-vep/vep \\\\\n",
    "        -i \\${TEST_VCF} \\\\\n",
    "        -o \\${OUTPUT_FILE} \\\\\n",
    "        --warning_file /tmp/vep_warnings.txt \\\\\n",
    "        --plugin LoF,loftee_path:\\${PLUGIN_DIR}/loftee,human_ancestor_fa:\\${HUMAN_ANCESTOR_FILE},human_ancestor_index:\\${HUMAN_ANCESTOR_INDEX},conservation_file:\\${CONSERVATION_FILE},gerp_bigwig:\\${GERP_FILE_PATH} \\\\\n",
    "        --plugin CADD,snv=\\${PLUGIN_DIR}/whole_genome_SNVs_inclAnno.tsv.gz,indels=\\${PLUGIN_DIR}/whole_genome_SNVs_inclAnno.tsv.gz \\\\\n",
    "        --plugin dbNSFP,\\${PLUGIN_DIR}/dbNSFP/dbNSFP4.9a_grch38.gz,Ensembl_transcriptid,Uniprot_acc,VEP_canonical,LRT_pred,SIFT_pred,MutationTaster_pred,Polyphen2_HDIV_pred,Polyphen2_HVAR_pred,REVEL_score \\\\\n",
    "        --plugin SpliceAI,snv=\\${PLUGIN_DIR}/spliceai_scores.raw.snv.hg38.vcf.gz,indel=\\${PLUGIN_DIR}/spliceai_scores.raw.indel.hg38.vcf.gz \\\\\n",
    "        --everything \\\\\n",
    "        --buffer_size 40000 \\\\\n",
    "        --fork 24 \\\\\n",
    "        --minimal \\\\\n",
    "        --offline \\\\\n",
    "        --dir_cache \\${EXTRACTED_CACHE_DIR} \\\\\n",
    "        --no_escape \\\\\n",
    "        --fasta \\${PLUGIN_DIR}/Homo_sapiens_assembly38.fasta \\\\\n",
    "        --hgvs \\\\\n",
    "        --cache \\\\\n",
    "        --format vcf \\\\\n",
    "        --force_overwrite \\\\\n",
    "        --tab \\\\\n",
    "        --dir_plugins \\${PLUGIN_DIR}\n",
    "      \n",
    "      echo 'VEP run for chromosome ${CHR} completed. Check the output at:' \\${OUTPUT_FILE}\n",
    "    \" &\n",
    "}\n",
    "\n",
    "# Launch VEP jobs for chromosomes # in parallel. This one is for 3 and 6 but adjust and add your chromosome numbers accordingly\n",
    "for chr in 3 21; do\n",
    "  run_vep_job $chr\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert normalized plink2 files to plink bim, fam, and bed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Load the aou_dsub helper\n",
    "source ~/aou_dsub.bash\n",
    "\n",
    "# Define common buckets\n",
    "USER_NAME=${USER_NAME:-$(whoami)}\n",
    "PLINK_BUCKET=\"gs://fc-secure-5e490ca2-d5ae-40a3-aa5e-7355e31ab9cc/chr_plinkID\"\n",
    "OUTPUT_BUCKET=\"gs://fc-secure-ba7f8e74-e9c2-44d2-a3d0-be0aada98680/AOU_v8.exome.normalized.plink2_files/bed_bim_fam_files\"\n",
    "LOGGING_BUCKET=\"${OUTPUT_BUCKET}/logging\"\n",
    "\n",
    "# Loop over chromosomes 1–22\n",
    "for CHR in {1..22}; do\n",
    "  JOB_NAME=\"plink2-chr${CHR}-${USER_NAME}\"\n",
    "\n",
    "  echo \"Submitting conversion job for chr${CHR}…\"\n",
    "\n",
    "  aou_dsub \\\n",
    "    --name \"${JOB_NAME}\" \\\n",
    "    --image \"gcr.io/ritchie-aou-psom-9015/plink2:latest\" \\\n",
    "    --logging \"${LOGGING_BUCKET}\" \\\n",
    "    --min-cores 4 \\\n",
    "    --min-ram 8 \\\n",
    "    --boot-disk-size 50 \\\n",
    "    --disk-size 1000 \\\n",
    "    --input INPUT_PGEN=\"${PLINK_BUCKET}/exome_v8.chr${CHR}.new_id.split_multiallelic.pass_qc.pgen\" \\\n",
    "    --input INPUT_PVAR=\"${PLINK_BUCKET}/exome_v8.chr${CHR}.new_id.split_multiallelic.pass_qc.pvar\" \\\n",
    "    --input INPUT_PSAM=\"${PLINK_BUCKET}/exome_v8.chr${CHR}.new_id.split_multiallelic.pass_qc.psam\" \\\n",
    "    --output OUTPUT_BED=\"${OUTPUT_BUCKET}/exome_v8.chr${CHR}.new_id.split_multiallelic.pass_qc.bed\" \\\n",
    "    --output OUTPUT_BIM=\"${OUTPUT_BUCKET}/exome_v8.chr${CHR}.new_id.split_multiallelic.pass_qc.bim\" \\\n",
    "    --output OUTPUT_FAM=\"${OUTPUT_BUCKET}/exome_v8.chr${CHR}.new_id.split_multiallelic.pass_qc.fam\" \\\n",
    "    --command \"\n",
    "      set -ex\n",
    "      echo 'Converting chr${CHR} pgen → bed/bim/fam…'\n",
    "      plink2 \\\n",
    "        --pfile /mnt/data/input/gs/fc-secure-5e490ca2-d5ae-40a3-aa5e-7355e31ab9cc/chr_plinkID/exome_v8.chr${CHR}.new_id.split_multiallelic.pass_qc \\\n",
    "        --make-bed \\\n",
    "        --out /mnt/data/output/gs/fc-secure-ba7f8e74-e9c2-44d2-a3d0-be0aada98680/AOU_v8.exome.normalized.plink2_files/bed_bim_fam_files/exome_v8.chr${CHR}.new_id.split_multiallelic.pass_qc\"        \n",
    "\n",
    "done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
